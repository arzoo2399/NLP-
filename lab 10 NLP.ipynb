{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE-1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CLGGhS-BsF2T"
   },
   "outputs": [],
   "source": [
    "sent = \"Rajkumar said on Monday that WASHINGTON -- In the wake of a string of abuses by New York police officers in the 1990s, Loretta E. Lynch, the top federal prosecutor in Brooklyn, spoke forcefully about the pain of a broken trust that African-Americans felt and said the responsibility for repairing generations of miscommunication and mistrust fell to law enforcement.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Lb-Q9d6QsdSt"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Arzoo\n",
      "[nltk_data]     Sah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Arzoo Sah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to C:\\Users\\Arzoo\n",
      "[nltk_data]     Sah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to C:\\Users\\Arzoo\n",
      "[nltk_data]     Sah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tree import Tree\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import ne_chunk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S i/NNS have/VBP talk/NN)\n"
     ]
    }
   ],
   "source": [
    "tok = word_tokenize('i have talk ')\n",
    "tagged = nltk.pos_tag(tok)\n",
    "ne_tree = nltk.ne_chunk(tagged,binary=False)\n",
    "print(ne_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXJor_h0eTXs"
   },
   "source": [
    "The sentence needs to be tokenized and add the pos tags and the tags are parsed into chunk trees. The nltk library has a pre-trained namied entity chunker which can be done using ne_chunk() method. The below code is an example of how to chunk the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7z3XtkZXDDRG",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON Rajkumar/NNP)\n",
      "  said/VBD\n",
      "  on/IN\n",
      "  Monday/NNP\n",
      "  that/IN\n",
      "  (ORGANIZATION WASHINGTON/NNP)\n",
      "  --/:\n",
      "  In/IN\n",
      "  the/DT\n",
      "  wake/NN\n",
      "  of/IN\n",
      "  a/DT\n",
      "  string/NN\n",
      "  of/IN\n",
      "  abuses/NNS\n",
      "  by/IN\n",
      "  (GPE New/NNP York/NNP)\n",
      "  police/NN\n",
      "  officers/NNS\n",
      "  in/IN\n",
      "  the/DT\n",
      "  1990s/CD\n",
      "  ,/,\n",
      "  (PERSON Loretta/NNP E./NNP Lynch/NNP)\n",
      "  ,/,\n",
      "  the/DT\n",
      "  top/JJ\n",
      "  federal/JJ\n",
      "  prosecutor/NN\n",
      "  in/IN\n",
      "  (GPE Brooklyn/NNP)\n",
      "  ,/,\n",
      "  spoke/VBD\n",
      "  forcefully/RB\n",
      "  about/IN\n",
      "  the/DT\n",
      "  pain/NN\n",
      "  of/IN\n",
      "  a/DT\n",
      "  broken/JJ\n",
      "  trust/NN\n",
      "  that/IN\n",
      "  African-Americans/NNP\n",
      "  felt/VBD\n",
      "  and/CC\n",
      "  said/VBD\n",
      "  the/DT\n",
      "  responsibility/NN\n",
      "  for/IN\n",
      "  repairing/VBG\n",
      "  generations/NNS\n",
      "  of/IN\n",
      "  miscommunication/NN\n",
      "  and/CC\n",
      "  mistrust/NN\n",
      "  fell/VBD\n",
      "  to/TO\n",
      "  law/NN\n",
      "  enforcement/NN\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "tok = word_tokenize(sent)\n",
    "tagged = nltk.pos_tag(tok)\n",
    "ne_tree = nltk.ne_chunk(tagged,binary=False)\n",
    "print(ne_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question-1\n",
    " Count and print the number of PERSON, LOCATION and ORGANIZATION in the given sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kxUcW6q9skl4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Counter({'Rajkumar': 1, 'NNP': 1})]\n",
      "[Counter({'WASHINGTON': 1, 'NNP': 1})]\n",
      "[Counter({'New': 1, 'NNP': 1}), Counter({'York': 1, 'NNP': 1})]\n",
      "[Counter({'Loretta': 1, 'NNP': 1}), Counter({'E.': 1, 'NNP': 1}), Counter({'Lynch': 1, 'NNP': 1})]\n",
      "[Counter({'Brooklyn': 1, 'NNP': 1})]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from collections import Counter   \n",
    "for chunk in ne_tree:\n",
    "    if hasattr(chunk, 'label'):\n",
    "        print([Counter(label) for label in chunk])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question-2\n",
    "Observe the results. Does named entity, “police officers” get recognized?.\n",
    "\n",
    "Write a regular expression patter to detect this. You will need nltk.RegexpParser class to define pattern and parse terms to detect patterns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MIA-AMLi4m8h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rajkumar', 'WASHINGTON', 'New York', 'police officers', 'Loretta E. Lynch', 'Brooklyn']\n"
     ]
    }
   ],
   "source": [
    "grammar = \"NP: {<NN><NNS>}\"\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "result = cp.parse(ne_tree)\n",
    "NE = [ \" \".join(w for w, t in ele) for ele in result if isinstance(ele, nltk.Tree)]   \n",
    "print(NE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Rajkumar', 'NNP'), ('said', 'VBD'), ('on', 'IN'), ('Monday', 'NNP'), ('that', 'IN'), ('WASHINGTON', 'NNP'), ('--', ':'), ('In', 'IN'), ('the', 'DT'), ('wake', 'NN'), ('of', 'IN'), ('a', 'DT'), ('string', 'NN'), ('of', 'IN'), ('abuses', 'NNS'), ('by', 'IN'), ('New', 'NNP'), ('York', 'NNP'), Tree('NP', [('police', 'NN'), ('officers', 'NNS')]), ('in', 'IN'), ('the', 'DT'), ('1990s', 'CD'), (',', ','), ('Loretta', 'NNP'), ('E.', 'NNP'), ('Lynch', 'NNP'), (',', ','), ('the', 'DT'), ('top', 'JJ'), ('federal', 'JJ'), ('prosecutor', 'NN'), ('in', 'IN'), ('Brooklyn', 'NNP'), (',', ','), ('spoke', 'VBD'), ('forcefully', 'RB'), ('about', 'IN'), ('the', 'DT'), ('pain', 'NN'), ('of', 'IN'), ('a', 'DT'), ('broken', 'JJ'), ('trust', 'NN'), ('that', 'IN'), ('African-Americans', 'NNP'), ('felt', 'VBD'), ('and', 'CC'), ('said', 'VBD'), ('the', 'DT'), ('responsibility', 'NN'), ('for', 'IN'), ('repairing', 'VBG'), ('generations', 'NNS'), ('of', 'IN'), ('miscommunication', 'NN'), ('and', 'CC'), ('mistrust', 'NN'), ('fell', 'VBD'), ('to', 'TO'), ('law', 'NN'), ('enforcement', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "out=cp.parse(tagged)\n",
    "print(out[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question-3\n",
    "Does the named entity, “the top federal prosecutor” get recognized?.\n",
    "\n",
    "Write a regular expression pattern to detect this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vIiriWhJ5HFq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rajkumar', 'WASHINGTON', 'the wake', 'a string', 'New York', 'Loretta E. Lynch', 'the top federal prosecutor', 'Brooklyn', 'the pain', 'a broken trust', 'the responsibility']\n"
     ]
    }
   ],
   "source": [
    "grammar = \"NP: {<DT><JJ>*<NN>}\"\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "result = cp.parse(ne_tree)\n",
    "NE = [ \" \".join(w for w, t in ele) for ele in result if isinstance(ele, nltk.Tree)]   \n",
    "print (NE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE-2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "yRJmpFdG_W3O"
   },
   "outputs": [],
   "source": [
    "sent2 = \"European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tree('GPE', [('European', 'JJ')]), ('authorities', 'NNS'), ('fined', 'VBD'), Tree('PERSON', [('Google', 'NNP')]), ('a', 'DT'), ('record', 'NN'), ('$', '$'), ('5.1', 'CD'), ('billion', 'CD'), ('on', 'IN'), ('Wednesday', 'NNP'), ('for', 'IN'), ('abusing', 'VBG'), ('its', 'PRP$'), ('power', 'NN'), ('in', 'IN'), ('the', 'DT'), ('mobile', 'JJ'), ('phone', 'NN'), ('market', 'NN'), ('and', 'CC'), ('ordered', 'VBD'), ('the', 'DT'), ('company', 'NN'), ('to', 'TO'), ('alter', 'VB'), ('its', 'PRP$'), ('practices', 'NNS')]\n"
     ]
    }
   ],
   "source": [
    "tok = word_tokenize(sent2)\n",
    "tagged = nltk.pos_tag(tok)\n",
    "ne_tree2 = nltk.ne_chunk(tagged,binary=False)\n",
    "print(ne_tree2[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question-1\n",
    "\n",
    "Observe the output. Does your code recognize the NE shown in BOLD?\n",
    "\n",
    "Write a regular expression that recognizes the entity, “$5.1 billion”\n",
    "Detect and print this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['European', 'Google', 'a record', '5.1', 'billion', 'the mobile phone', 'the company']\n"
     ]
    }
   ],
   "source": [
    "grammar = \"NP: {<CD>|<DT><JJ>*<NN>}\"\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "result = cp.parse(ne_tree2)\n",
    "NE = [ \" \".join(w for w, t in ele) for ele in result if isinstance(ele, nltk.Tree)]   \n",
    "print (NE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question-2\n",
    "Write a regular expression that recognizes the entity, “the mobile phone” and similar to this entity such as “the company\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['European', 'Google', 'a record', 'the mobile phone', 'the company']\n"
     ]
    }
   ],
   "source": [
    "grammar = \"NP: {<DT><JJ>*<NN>}\"\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "result = cp.parse(ne_tree2)\n",
    "NE = [ \" \".join(w for w, t in ele) for ele in result if isinstance(ele, nltk.Tree)]   \n",
    "print (NE)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Lab_10_starter_notebook_NER_using_nltk.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
