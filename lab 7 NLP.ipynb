{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "synthetic-render",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-scholar",
   "metadata": {},
   "source": [
    "## EXERCISE-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-reading",
   "metadata": {},
   "source": [
    "### 1. Open the file, 'rotten_tomato_train.tsv' and read into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hazardous-remark",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotten_tomato_train = pd.read_csv('rotten_tomato_train.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "enhanced-stewart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotten_tomato_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-point",
   "metadata": {},
   "source": [
    "### 2. Print the basic statistics such as head, shape, describe, and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "brilliant-lobby",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>156056</td>\n",
       "      <td>8544</td>\n",
       "      <td>Hearst 's</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>156057</td>\n",
       "      <td>8544</td>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>156058</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>156059</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>156060</td>\n",
       "      <td>8544</td>\n",
       "      <td>chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId                     Phrase  Sentiment\n",
       "156055    156056        8544                  Hearst 's          2\n",
       "156056    156057        8544  forced avuncular chortles          1\n",
       "156057    156058        8544         avuncular chortles          3\n",
       "156058    156059        8544                  avuncular          2\n",
       "156059    156060        8544                   chortles          2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotten_tomato_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wired-implementation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotten_tomato_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dying-merchandise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of         PhraseId  SentenceId  \\\n",
       "0              1           1   \n",
       "1              2           1   \n",
       "2              3           1   \n",
       "3              4           1   \n",
       "4              5           1   \n",
       "...          ...         ...   \n",
       "156055    156056        8544   \n",
       "156056    156057        8544   \n",
       "156057    156058        8544   \n",
       "156058    156059        8544   \n",
       "156059    156060        8544   \n",
       "\n",
       "                                                   Phrase  Sentiment  \n",
       "0       A series of escapades demonstrating the adage ...          1  \n",
       "1       A series of escapades demonstrating the adage ...          2  \n",
       "2                                                A series          2  \n",
       "3                                                       A          2  \n",
       "4                                                  series          2  \n",
       "...                                                   ...        ...  \n",
       "156055                                          Hearst 's          2  \n",
       "156056                          forced avuncular chortles          1  \n",
       "156057                                 avuncular chortles          3  \n",
       "156058                                          avuncular          2  \n",
       "156059                                           chortles          2  \n",
       "\n",
       "[156060 rows x 4 columns]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotten_tomato_train.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "frozen-deployment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PhraseId', 'SentenceId', 'Phrase', 'Sentiment'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotten_tomato_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-straight",
   "metadata": {},
   "source": [
    "### 3. How many reviews exist for each sentiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "mighty-minutes",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "0     7072\n",
       "1    27273\n",
       "2    79582\n",
       "3    32927\n",
       "4     9206\n",
       "Name: Phrase, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review=rotten_tomato_train.groupby('Sentiment').count()\n",
    "review.Phrase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-jefferson",
   "metadata": {},
   "source": [
    "## EXERCISE-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-northeast",
   "metadata": {},
   "source": [
    "### 1. Extract 200 reviews for each sentiment, store them into a new dataframe and create a smaller dataset. Save this dataframe in a new file, say, “small_rotten_train.csv”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "coastal-british",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=rotten_tomato_train.loc[rotten_tomato_train.Sentiment == 0]\n",
    "b=rotten_tomato_train.loc[rotten_tomato_train.Sentiment == 1]\n",
    "c=rotten_tomato_train.loc[rotten_tomato_train.Sentiment == 2]\n",
    "d=rotten_tomato_train.loc[rotten_tomato_train.Sentiment == 3]\n",
    "e=rotten_tomato_train.loc[rotten_tomato_train.Sentiment == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "skilled-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_rotten_train=pd.concat([a[:200],b[:200],c[:200],d[:200],e[:200]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-species",
   "metadata": {},
   "source": [
    "## EXERCISE-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-charity",
   "metadata": {},
   "source": [
    "### 1. Open the file, “small_rotten_train.csv”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "increasing-ground",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>would have a hard time sitting through this one</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>have a hard time sitting through this one</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>158</td>\n",
       "      <td>5</td>\n",
       "      <td>Aggressive self-glorification and a manipulati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>160</td>\n",
       "      <td>5</td>\n",
       "      <td>self-glorification and a manipulative whitewash</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>202</td>\n",
       "      <td>7</td>\n",
       "      <td>Trouble Every Day is a plodding mess .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3744</th>\n",
       "      <td>3745</td>\n",
       "      <td>142</td>\n",
       "      <td>amazing slapstick</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3745</th>\n",
       "      <td>3746</td>\n",
       "      <td>142</td>\n",
       "      <td>amazing</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3847</th>\n",
       "      <td>3848</td>\n",
       "      <td>147</td>\n",
       "      <td>When cowering and begging at the feet a scruff...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3866</th>\n",
       "      <td>3867</td>\n",
       "      <td>147</td>\n",
       "      <td>gives her best performance since Abel Ferrara ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3993</th>\n",
       "      <td>3994</td>\n",
       "      <td>151</td>\n",
       "      <td>Spielberg 's realization of a near-future Amer...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PhraseId  SentenceId                                             Phrase  \\\n",
       "101        102           3    would have a hard time sitting through this one   \n",
       "103        104           3          have a hard time sitting through this one   \n",
       "157        158           5  Aggressive self-glorification and a manipulati...   \n",
       "159        160           5    self-glorification and a manipulative whitewash   \n",
       "201        202           7             Trouble Every Day is a plodding mess .   \n",
       "...        ...         ...                                                ...   \n",
       "3744      3745         142                                  amazing slapstick   \n",
       "3745      3746         142                                            amazing   \n",
       "3847      3848         147  When cowering and begging at the feet a scruff...   \n",
       "3866      3867         147  gives her best performance since Abel Ferrara ...   \n",
       "3993      3994         151  Spielberg 's realization of a near-future Amer...   \n",
       "\n",
       "      Sentiment  \n",
       "101           0  \n",
       "103           0  \n",
       "157           0  \n",
       "159           0  \n",
       "201           0  \n",
       "...         ...  \n",
       "3744          4  \n",
       "3745          4  \n",
       "3847          4  \n",
       "3866          4  \n",
       "3993          4  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_rotten_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-economy",
   "metadata": {},
   "source": [
    "### 2. The review text are stored in “Phrase” column. Extract that into a separate DataFrame, say “X”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "emotional-devices",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = small_rotten_train.Phrase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-drain",
   "metadata": {},
   "source": [
    "### 3. The “sentiment” column is your target, say “y”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "starting-enclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = small_rotten_train.Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-telephone",
   "metadata": {},
   "source": [
    "### 4. Perform pre-processing: convert into lower case, remove stop words and lemmatize. The following function will help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "chemical-satisfaction",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Arzoo\n",
      "[nltk_data]     Sah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "referenced-technical",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bottom-letter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review(review):\n",
    "    tokens = review.lower().split()\n",
    "    filtered_tokens = [lemmatizer.lemmatize(w) for w in tokens if w not in stop_words]\n",
    "    return \" \".join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-commander",
   "metadata": {},
   "source": [
    "### 5. Apply the above function to X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "naked-shell",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=X.tolist()\n",
    "fax=[]\n",
    "for i in temp:\n",
    "    fax.append(clean_review(i))\n",
    "n_X=pd.Series(fax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incomplete-withdrawal",
   "metadata": {},
   "source": [
    "### 6. Split X and y for training and testing (Use 20% for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "brazilian-visitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "appointed-champion",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(n_X,y,train_size=0.8,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-river",
   "metadata": {},
   "source": [
    "### 7. Create TfidfVectorizer as below and perfrom vectorization on X_train using fit_perform() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "respected-uganda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "herbal-jonathan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(min_df=3, ngram_range=(1, 2), use_idf=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf=TfidfVectorizer(min_df=3, max_features=None,ngram_range=(1, 2), use_idf=1)\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "urban-henry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 874)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=tf.fit_transform(X_train)\n",
    "m.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-robertson",
   "metadata": {},
   "source": [
    "### 8. Create MultinomialNB model and perform training using X_train_lemmartized and y_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "sticky-identity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "brown-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dtm = cv.fit_transform(X_train)\n",
    "X_test_dtm = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "national-action",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "honest-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "straight-witness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_dtm,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-organizer",
   "metadata": {},
   "source": [
    "### 9. Perform validation on X_test lemmatized and predict output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "selective-reader",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 4, 0, 0, 4, 2, 2, 3, 3, 1, 3, 0, 3, 2, 4, 1, 1, 1, 2, 3, 4,\n",
       "       3, 4, 3, 3, 4, 3, 1, 3, 1, 3, 4, 0, 3, 2, 0, 2, 1, 4, 1, 0, 3, 1,\n",
       "       1, 1, 3, 3, 1, 0, 3, 1, 3, 3, 0, 0, 2, 1, 2, 2, 2, 4, 3, 3, 3, 3,\n",
       "       0, 2, 1, 1, 4, 2, 3, 2, 3, 2, 4, 3, 1, 2, 4, 4, 3, 3, 1, 3, 4, 1,\n",
       "       2, 3, 1, 3, 3, 3, 2, 3, 4, 4, 3, 2, 2, 1, 3, 3, 1, 2, 3, 2, 3, 1,\n",
       "       2, 1, 3, 4, 2, 0, 4, 0, 4, 0, 4, 1, 0, 3, 1, 3, 1, 0, 3, 3, 0, 3,\n",
       "       1, 0, 2, 0, 4, 3, 0, 3, 0, 2, 0, 3, 2, 0, 4, 1, 4, 2, 0, 1, 4, 3,\n",
       "       2, 2, 2, 2, 0, 0, 3, 3, 2, 0, 3, 1, 4, 2, 1, 1, 0, 3, 1, 4, 0, 4,\n",
       "       4, 2, 1, 2, 0, 0, 2, 1, 4, 3, 1, 4, 1, 3, 4, 1, 0, 3, 0, 1, 4, 3,\n",
       "       2, 3], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_real_pred = clf.predict(X_test_dtm)\n",
    "y_real_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-turner",
   "metadata": {},
   "source": [
    "### 10. Print classification_report and accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "particular-rescue",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "right-liberia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.73      0.78        37\n",
      "           1       0.65      0.59      0.62        44\n",
      "           2       0.66      0.54      0.60        46\n",
      "           3       0.44      0.76      0.56        33\n",
      "           4       0.73      0.60      0.66        40\n",
      "\n",
      "    accuracy                           0.64       200\n",
      "   macro avg       0.66      0.64      0.64       200\n",
      "weighted avg       0.67      0.64      0.64       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_real_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "extra-regard",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "respected-surveillance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.635"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_real_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-harrison",
   "metadata": {},
   "source": [
    "## EXERCISE-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "armed-desperate",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotten_tomato_test = pd.read_csv('rotten_tomato_test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "generous-little",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66292, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotten_tomato_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "located-encounter",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = rotten_tomato_test.Phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "formed-disposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_temp=X_.tolist()\n",
    "t_fax=[]\n",
    "for i in t_temp:\n",
    "    t_fax.append(clean_review(i))\n",
    "nt_X=pd.Series(t_fax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "productive-member",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        intermittently pleasing mostly routine effort .\n",
       "1          intermittently pleasing mostly routine effort\n",
       "2                                                       \n",
       "3          intermittently pleasing mostly routine effort\n",
       "4                 intermittently pleasing mostly routine\n",
       "                              ...                       \n",
       "66287               long-winded , predictable scenario .\n",
       "66288                 long-winded , predictable scenario\n",
       "66289                                      long-winded ,\n",
       "66290                                        long-winded\n",
       "66291                               predictable scenario\n",
       "Length: 66292, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nt_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fallen-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "infrared-logan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(ngram_range=(1, 3))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf2=TfidfVectorizer(use_idf=True,ngram_range=(1,3),min_df = 1)\n",
    "tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "pointed-allowance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<66292x61283 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 571899 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my2=tf2.fit_transform(nt_X)\n",
    "my2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-soldier",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
