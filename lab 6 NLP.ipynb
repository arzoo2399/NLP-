{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "guilty-adolescent",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-texture",
   "metadata": {},
   "source": [
    "### 1. Open “SMSSpamCollection” file and load into DataFrame. It contains two columns “label” and “text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "changed-beijing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"SMSSpamCollection.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deluxe-battle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will �_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham              Will �_ b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms=df.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis=1)\n",
    "sms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-craps",
   "metadata": {},
   "source": [
    "### 2. How many sms messages are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "removable-assets",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-friday",
   "metadata": {},
   "source": [
    "### 3. How many “ham” and “spam” messages?. You need to groupby() label column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accredited-limitation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text\n",
       "label      \n",
       "ham    4825\n",
       "spam    747"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=sms.groupby('label').count()\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-paste",
   "metadata": {},
   "source": [
    "### 4. Split the dataset into training set and test set (Use 20% of data for testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "first-violin",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sms.text\n",
    "y = sms.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "racial-porter",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "modern-membership",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.8,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-furniture",
   "metadata": {},
   "source": [
    "### 5. Create a function that will remove all punctuation characters and stop words, as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "anonymous-marble",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(msg):\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    nopunc =[char for char in msg if char not in punctuations]\n",
    "    nopunc=''.join(nopunc)\n",
    "    return [word for word in nopunc.split()\n",
    "    if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-adoption",
   "metadata": {},
   "source": [
    "### 6. Create TfIdfVectorizer as below and perform vectorization on X_train, using fit_perform() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "capital-senate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "speaking-barbados",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer=<function process_text at 0x000001D510FDA820>,\n",
       "                ngram_range=(1, 3), stop_words='english')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf2=TfidfVectorizer(use_idf=True,analyzer=process_text,ngram_range=(1,3),min_df = 1,stop_words = 'english')\n",
    "tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "piano-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2=tf2.fit_transform(X_train)\n",
    "my2=tf2.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "iraqi-patrol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457, 9960)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "authentic-charge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1115, 9960)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-jumping",
   "metadata": {},
   "source": [
    "### 7. Create MultinomialNB model and perform training on X_train and y_train using fit() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "internal-element",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,Y_train,Y_test = train_test_split(X,y,train_size=0.8,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "precise-humor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ideal-metadata",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "broad-baseline",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(m2,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-asset",
   "metadata": {},
   "source": [
    "### 8. Predict labels on the test set, using predict() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "pediatric-engineer",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'ham', 'ham', ..., 'ham', 'ham', 'ham'], dtype='<U4')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(my2)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "substantial-enzyme",
   "metadata": {},
   "source": [
    "### 9. Print confusion_matrix and classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "military-norman",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "stuck-humanitarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[952,   0],\n",
       "       [ 47, 116]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "considered-specialist",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "metropolitan-viking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.95      1.00      0.98       952\n",
      "     class 1       1.00      0.71      0.83       163\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.98      0.86      0.90      1115\n",
      "weighted avg       0.96      0.96      0.95      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-siemens",
   "metadata": {},
   "source": [
    "### 10. Modify ngram_range=(1,2) and perform Steps 7 to 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "parental-effect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer=<function process_text at 0x000001D510FDA820>,\n",
       "                ngram_range=(1, 2), stop_words='english')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf3=TfidfVectorizer(use_idf=True,analyzer=process_text,ngram_range=(1,2),min_df = 1,stop_words = 'english')\n",
    "tf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "clean-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3=tf3.fit_transform(X_train)\n",
    "my3=tf3.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "approved-productivity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457, 9960)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "environmental-transmission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1115, 9960)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fitting-philippines",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(m3,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "serious-african",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'ham', 'ham', ..., 'ham', 'ham', 'ham'], dtype='<U4')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred3 = clf.predict(my3)\n",
    "y_pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "stable-farmer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[952,   0],\n",
       "       [ 47, 116]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "heated-reward",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.95      1.00      0.98       952\n",
      "     class 1       1.00      0.71      0.83       163\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.98      0.86      0.90      1115\n",
      "weighted avg       0.96      0.96      0.95      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test,y_pred3,target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
