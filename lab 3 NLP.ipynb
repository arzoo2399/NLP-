{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERSICE - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t0.7071067811865476\n",
      "  (0, 2)\t0.7071067811865476\n",
      "  (1, 3)\t0.5773502691896257\n",
      "  (1, 0)\t0.5773502691896257\n",
      "  (1, 2)\t0.5773502691896257\n",
      "  (2, 1)\t0.7071067811865476\n",
      "  (2, 3)\t0.7071067811865476\n",
      "  (3, 1)\t1.0\n"
     ]
    }
   ],
   "source": [
    "docs = [\"good movie\", \"not a good movie\", \"did not like\",\"i like it\", \"good one\" ]\n",
    "# using default tokenizer in TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1, 2))\n",
    "features = tfidf.fit_transform(docs)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   good movie      like     movie       not\n",
      "0    0.707107  0.000000  0.707107  0.000000\n",
      "1    0.577350  0.000000  0.577350  0.577350\n",
      "2    0.000000  0.707107  0.000000  0.707107\n",
      "3    0.000000  1.000000  0.000000  0.000000\n",
      "4    0.000000  0.000000  0.000000  0.000000\n"
     ]
    }
   ],
   "source": [
    "# Pretty printing\n",
    "df = pd.DataFrame(features.todense(),columns=tfidf.get_feature_names())\n",
    "print(df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXCERSICE - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1.0\n",
      "  (1, 0)\t1.0\n",
      "  (4, 0)\t1.0\n"
     ]
    }
   ],
   "source": [
    "docs = [\"good movie\", \"not a good movie\", \"did not like\",\"i like it\", \"good one\" ]\n",
    "# using default tokenizer in TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(min_df=3, max_df=1.5, ngram_range=(1,2))\n",
    "features2 = tfidf.fit_transform(docs)\n",
    "print(features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1.0\n",
      "  (1, 2)\t0.7071067811865476\n",
      "  (1, 1)\t0.7071067811865476\n",
      "  (2, 0)\t0.7071067811865476\n",
      "  (2, 2)\t0.7071067811865476\n",
      "  (3, 0)\t1.0\n"
     ]
    }
   ],
   "source": [
    "docs = [\"good movie\", \"not a good movie\", \"did not like\",\"i like it\", \"good one\" ]\n",
    "# using default tokenizer in TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(0,1))\n",
    "features3 = tfidf.fit_transform(docs)\n",
    "print(features3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXCERSICE - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.81649658]]\n"
     ]
    }
   ],
   "source": [
    "# cosine score between 1st and 2nd doc\n",
    "doc1 = features[0:1]\n",
    "doc2 = features[1:2]\n",
    "score = linear_kernel(doc1, doc2)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.81649658 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# cosine score between 1st and all other docs\n",
    "scores = linear_kernel(doc1, features)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.81649658 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Cosine Similarity for a new doc\n",
    "query = \"I like this good movie\"\n",
    "qfeature = tfidf.transform([query])\n",
    "scores2 = linear_kernel(doc1,features)\n",
    "print(scores2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERSICE - 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3)\t0.7071067811865476\n",
      "  (0, 1)\t0.7071067811865476\n",
      "  (1, 2)\t0.7071067811865476\n",
      "  (1, 0)\t0.7071067811865476\n",
      "  (2, 3)\t0.7071067811865476\n",
      "  (2, 1)\t0.7071067811865476\n",
      "  (3, 2)\t0.7071067811865476\n",
      "  (3, 0)\t0.7071067811865476\n"
     ]
    }
   ],
   "source": [
    "docx=[\"the house had a tiny little mouse\",\"the cat saw the mouse\",\"the mouse ran away from the house\",\"the cat finally ate the mouse\",\"the end of the mouse story\"]\n",
    "# using default tokenizer in TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1, 2))\n",
    "feat = tfidf.fit_transform(docx)\n",
    "print(feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question-2. Compute cosine similarity between 3rd document (“the mouse ran away from the house”) with all other documents. Which is the most similar document?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 1. 0.]\n",
      " [1. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#cosine similarity between 3rd and all doc \n",
    "doc1 = feat[0:3]\n",
    "score = linear_kernel(doc1,feat)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 1. 0.]\n",
      " [1. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "score2 = linear_kernel(doc1,feat)\n",
    "print(score2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
